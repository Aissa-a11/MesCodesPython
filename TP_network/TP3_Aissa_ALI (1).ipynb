{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
    "\n",
    "We can use the following libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.2 |Continuum Analytics, Inc.| (default, Jul 20 2017, 12:30:02) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: preliminary work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Using the code seen in previous TPs, load the following graph as a dictonary of lists:\n",
    "\n",
    "http://lioneltabourier.fr/documents/inet.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_graph(file):\n",
    "    f = open(file, 'r')\n",
    "    contenu=f.read() \n",
    "    Liste=contenu.split( )\n",
    "    d={}\n",
    "    for l in Liste:\n",
    "        d[l]=[]\n",
    "    j=0   \n",
    "    for j in range(len(Liste)-1):\n",
    "             for k in d.keys():\n",
    "                   if k==Liste[j]:\n",
    "                        if j%2==0:\n",
    "                            d[k].append(Liste[j+1])\n",
    "                        if j%2!=0:\n",
    "                            d[k].append(Liste[j-1])\n",
    "    f.close()\n",
    "    return(d)\n",
    "g=load_graph(\"inet.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Determine the size of the largest connected component (LCC) of a graph, and use the code to determine the size of the LCC of the example graph.\n",
    "\n",
    "Possible implementation:\n",
    "\n",
    "- Create a function that takes a graph as input and outputs a dictionary of the connected component that each node belongs to. (This function is derived from a BFS).\n",
    "\n",
    "- Then, create another function which takes a dictionary of the connected component that each node belongs to and outputs the size of the largest connected component of the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8557\n",
      "le temps d éxecution du programme est: 0:00:33.936084\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def BFS(graph,s): \n",
    "    \n",
    "    queue=[s]\n",
    "    dist={}\n",
    "    visited=[]\n",
    "\n",
    "    dist[s]=0\n",
    "   \n",
    "    while queue:\n",
    "        node=queue.pop(0)\n",
    "        #visited.append(node)\n",
    "        try:\n",
    "            for neighbour in graph[node]:\n",
    "                if neighbour not in visited:\n",
    "                        visited.append(neighbour)\n",
    "                        dist[neighbour]=dist[node]+1\n",
    "                        queue.append(neighbour)\n",
    "        except KeyError:\n",
    "            continue\n",
    "        \n",
    "    return visited\n",
    "\n",
    "\n",
    "def LargestConnectedComponent(graph):\n",
    "    LCC=0\n",
    "    v=[]\n",
    "    for i in graph:\n",
    "        while i not in v:\n",
    "            BFS(g,i)\n",
    "            for m in BFS(g,i):\n",
    "                v.append(m)\n",
    "            if len(BFS(g,i))>LCC:\n",
    "                LCC=len(BFS(g,i))\n",
    "    return LCC\n",
    "start_time =datetime.now()\n",
    "print(LargestConnectedComponent(g)) \n",
    "\n",
    "end_time=datetime.now()\n",
    "print('le temps d éxecution du programme est: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: robustness to random failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "In this question, we plot the size of the LCC as a function of a number of randomly chosen nodes which are removed. This is a way to evaluate the robustness of the network to random failures.\n",
    "\n",
    "Possible implementation:\n",
    "\n",
    "- create a function that deletes $n_s$ nodes from the original graph\n",
    "\n",
    "- use the function of question 2 to compute the size of the LCC\n",
    "\n",
    "- combine these two functions and iterate to get a dictionary which keys are $n_s$ and values are the corresponding size of the LCC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a function that deletes  nsns  nodes from the original graph\n",
    "import random\n",
    "def DeleteNodes(graph,n):\n",
    "    h=[]\n",
    "    N=[]\n",
    "    for i in graph:\n",
    "        h.append(i)\n",
    "    for s in range(n):\n",
    "        k=random.choice(h)\n",
    "        N.append(k)\n",
    "        if k in graph:\n",
    "            graph.pop(k)\n",
    "    print(N)        \n",
    "    \n",
    "    for node in graph.keys():\n",
    "         \n",
    "        for l in graph[node]:\n",
    "            if k in graph[node]:\n",
    "                graph[node].remove(k)\n",
    "    \n",
    "    return graph\n",
    "                \n",
    "#DeleteNodes(g,8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the size of the LCC after deleting \n",
    "#it takes a lot of time\n",
    "gr=load_graph(\"graphs.txt\")\n",
    "def LccDeleteNodes(graph,n):\n",
    "    listeLcc=[]\n",
    "    #y=LargestConnectedComponent(graph)\n",
    "    for j in range(n):\n",
    "        DeleteNodes(graph,n)\n",
    "        y=LargestConnectedComponent(graph)\n",
    "        #print(y)\n",
    "        listeLcc.append(y)\n",
    "        \n",
    "    return listeLcc\n",
    "Y=LccDeleteNodes(g, 4)\n",
    "y=[8553, 8549, 8545, 8541]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=4\n",
    "X=[]\n",
    "for i in range(n):\n",
    "    X.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#graphe représantant les largeurs des composante connexes en fonction des noeuds supprimés\n",
    "plt(X,y)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: robustness to degree-based failures "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "In this question, we do the same as in the previous question, except for the fact that nodes are not chosen randomly, but by decreasing degree order.\n",
    "\n",
    "Possible implementation:\n",
    "\n",
    "- create a function that outputs a list of nodes ordered by decreasing degree\n",
    "\n",
    "- then follow the same principle as in the previous question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decreasingDegree(graph):\n",
    "    degree={}\n",
    "    for node in graph:\n",
    "        x=len(node)\n",
    "        degree[node]=x\n",
    "        sorted_degree=sorted(degree.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_degree\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Do the same robustness study as in the previous question but by decreasing closeness centrality order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
